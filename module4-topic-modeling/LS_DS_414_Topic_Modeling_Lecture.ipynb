{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSPT6_LS_DS_414_Topic_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cOMBkFKn6uEK"
      },
      "source": [
        "# Topic Modeling (Prepare)\n",
        "\n",
        "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
        "\n",
        "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
        "\n",
        "## Use Cases\n",
        "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
        "* Identifying common themes in customer reviews\n",
        "* Discovering the needle in a haystack \n",
        "* Monitoring communications (Email - State Department) \n",
        "\n",
        "## Learning Objectives\n",
        "*At the end of the lesson you should be able to:*\n",
        "* Part 0: Warm-Up\n",
        "* Part 1: Describe how an LDA Model works\n",
        "* Part 2: Estimate a LDA Model with Gensim\n",
        "* Part 3: Interpret LDA results & Select the appropriate number of topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cxH0cRGX6uEL"
      },
      "source": [
        "# Part 0: Warm-Up\n",
        "How do we do a grid search? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFjplZ7r3Lyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rnyNg8sQ6uEL",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "boKWVkRz6uEO",
        "colab": {}
      },
      "source": [
        "data = fetch_20newsgroups()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hPpukADi7Ofv",
        "colab": {}
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g9Jhb3j-7_e2",
        "colab": {}
      },
      "source": [
        "data['target_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JbVoIoMm8HbR",
        "colab": {}
      },
      "source": [
        "data['data'][1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w-39zg9a6uEQ"
      },
      "source": [
        "### GridSearch on Just Classifier\n",
        "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2q3NmHEo6uEQ",
        "colab": {}
      },
      "source": [
        "v1 = TfidfVectorizer()\n",
        "X_train = v1.fit_transform(data['data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LX3a4nUI6uES",
        "colab": {}
      },
      "source": [
        "p1 = {\n",
        "    'n_estimators':[10,20],\n",
        "    'max_depth': [None, 7]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7OfA7KNQ6uEU",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "gs1 = GridSearchCV(clf, p1, cv=5,n_jobs=-1, verbose=1)\n",
        "gs1.fit(X_train, data['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cMq_hw5W6uEX",
        "colab": {}
      },
      "source": [
        "#gs1.predict([\"Sample text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDkMaXvG83Zt",
        "colab": {}
      },
      "source": [
        "test_sample = v1.transform([\"Sample text\"])\n",
        "test_sample.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BLgsZtKJ8o01",
        "colab": {}
      },
      "source": [
        "pred = gs1.predict(test_sample)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLGkB8Vz9Otq",
        "colab": {}
      },
      "source": [
        "data['target_names'][pred[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WdVTuXKl6uEZ"
      },
      "source": [
        "### GridSearch with BOTH the Vectoizer & Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "97TjUtoI6uEZ",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Create a pipeline with a vectorize and a classifier\n",
        "# 2. Use Grid Search to optimize the entire pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IdIE67Us6uEc",
        "colab": {}
      },
      "source": [
        "pred = gs2.predict([\"Sample text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xhcb5G0W-Dch",
        "colab": {}
      },
      "source": [
        "data['target_names'][pred[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F2R2ACd36uEd"
      },
      "source": [
        "Advantages to using GS with the Pipe:\n",
        "* Allows us to make predictions on raw text increasing reproducibility. :)\n",
        "* Allows us to tune the parameters of the vectorizer along side the classifier. :D "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xbZjG6U86uEe"
      },
      "source": [
        "# Part 1: Describe how an LDA Model works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMzU-XOM3LzW",
        "colab_type": "text"
      },
      "source": [
        "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n",
        "\n",
        "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/)\n",
        "\n",
        "[Topic Modeling with Gensim](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yPIlE_IeF0cX",
        "colab": {}
      },
      "source": [
        "# Download spacy model\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qapChu_UGBFc",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "import spacy\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qaMsy1XAGLxc",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'content': data['data'],\n",
        "    'target': data['target'],\n",
        "    'target_names': [data['target_names'][i] for i in data['target']]\n",
        "})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "na2bkOcFGter",
        "colab": {}
      },
      "source": [
        "# For reference on regex: https://docs.python.org/3/library/re.html\n",
        "\n",
        "# From 'content' column: \n",
        "# 1. Remove whitespace \n",
        "\n",
        "# 2. Remove Emails\n",
        "\n",
        "# 3. Remove new line characters\n",
        "\n",
        "# 4. Remove non-alphanumeric characters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2prKILFo3Lzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkgfv9tc3Lzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize(progress_bar=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSW10Cb33Lzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6EBPQXqEKE9P",
        "colab": {}
      },
      "source": [
        "# Create 'lemmas' column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yvsyIpvKBlw",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPuCuK0z3Lzs",
        "colab_type": "text"
      },
      "source": [
        "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1klqRpqtJxWc",
        "colab": {}
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(df['lemmas'] )\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in df['lemmas']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ArZPxcP5LH1J",
        "colab": {}
      },
      "source": [
        "id2word[200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IIBnI2e3Lzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['content'][5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGFG9E2j3Lzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB6wox963Lz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word[252]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk3g75XX3Lz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word[276]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6K2jWxHJLOzK",
        "colab": {}
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[(id2word[word_id], word_count) for word_id, word_count in corpus[5]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le-XzI923Lz8",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Estimate a LDA Model with Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlNG4bSI3Lz8",
        "colab_type": "text"
      },
      "source": [
        " ### Train an LDA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fasvjf0VLQ2a",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "#                                            id2word=id2word,\n",
        "#                                            num_topics=20, \n",
        "#                                            chunksize=100,\n",
        "#                                            passes=10,\n",
        "#                                            per_word_topics=True)\n",
        "\n",
        "# # https://radimrehurek.com/gensim/models/ldamodel.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49CabmIj3Lz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lda_model.save('lda_model.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDgUshRE3L0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "#                                                         id2word=id2word,\n",
        "#                                                         num_topics=20, \n",
        "#                                                         chunksize=100,\n",
        "#                                                         passes=10,\n",
        "#                                                         per_word_topics=True,\n",
        "#                                                         workers=12)\n",
        "\n",
        "# # https://radimrehurek.com/gensim/models/ldamulticore.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgb9AaPq3L0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lda_multicore.save('lda_multicore.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLxvJPoK3L0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import models\n",
        "lda_multicore =  models.LdaModel.load('lda_multicore.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDH3tzx13L0I",
        "colab_type": "text"
      },
      "source": [
        "### View the topics in LDA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JawR8yscLVNS",
        "colab": {}
      },
      "source": [
        "pprint(lda_multicore.print_topics())\n",
        "doc_lda = lda_multicore[corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKEP0bIC3L0K",
        "colab_type": "text"
      },
      "source": [
        "### What is topic Perplexity?\n",
        "Perplexity is a statistical measure of how well a probability model predicts a sample. As applied to LDA, for a given value of , you estimate the LDA model. Then given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents.\n",
        "\n",
        "### What is topic coherence?\n",
        "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
        "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xCjhr8k4LXSy",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_multicore.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_multicore, \n",
        "                                     texts=df['lemmas'], \n",
        "                                     dictionary=id2word, \n",
        "                                     coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UvfgYt93L0X",
        "colab_type": "text"
      },
      "source": [
        "# Part 3: Interpret LDA results & Select the appropriate number of topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CYXi480VLaHK",
        "colab": {}
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_multicore, corpus, id2word)\n",
        "pyLDAvis.display(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rjtXk8J3LaXC",
        "colab": {}
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "                                                        id2word=id2word,\n",
        "                                                        num_topics=num_topics, \n",
        "                                                        chunksize=100,\n",
        "                                                        passes=10,\n",
        "                                                        per_word_topics=True,\n",
        "                                                        workers=12)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRA9EjvQ3L0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=df['lemmas'], start=2, limit=40, step=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e9X-Ql-3L0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coherence_values = [0.5054, 0.5332, 0.5452, 0.564, 0.5678, 0.5518, 0.519]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybEBYQNF3L0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmvQ2zKZ3L0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yol5vG3R3L0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the model and print the topics\n",
        "#optimal_model = model_list[4]\n",
        "optimal_model =  models.LdaModel.load('optimal_model.model')\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HwVEUDI3L0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}